# -*- coding: utf-8 -*-
import numpy as np
from torch.utils.data.dataset import Dataset
from torch.utils.data import ConcatDataset, DataLoader
from torch import optim
from torchvision import models, transforms
import torchvision.transforms as transforms
import torchvision
from torchvision.transforms import functional as TF
import torch.nn.functional as F
import torch.nn as nn
import torch
from torch.autograd import Function
import matplotlib.pyplot as plt
import pandas as pd
import random
import os
import sys
import glob
"""DLCVHW2_p3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pyXQg320hHN6sFTziper7X4qtGAkn6zd
"""

# !gdown - -id 1YxkObGDlqZM0-9Zq-QMjk7q1vND4UJl3 - -output "data.zip"
# ! unzip data.zip

# import module


# seed setting

def same_seeds(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True


same_seeds(1126)

# test_workspace_dir = '../hw2_data/digits/svhn/val/'
# test_workspace_dir = '../hw2_data/digits/usps/val/'
test_workspace_dir = sys.argv[1]
# output_dir = 'p3_svhn_output.csv'
# output_dir = 'p3_usps_output.csv'
output_dir = sys.argv[2]

# model_path_feature = './model/extractor_model_mnistm2svhn_best.bin'
# model_path_label = './model/predictor_model_mnistm2svhn_best.bin'
# model_path_feature = './model/extractor_model_mnistm2usps_best.bin'
# model_path_label = './model/predictor_model_mnistm2usps_best.bin'

model_path_feature = 'extractor_model_mnistm2svhn_best_rgb.bin'
model_path_label = 'predictor_model_mnistm2svhn_best_rgb.bin'
if "svhn" in test_workspace_dir:
    model_path_feature = 'extractor_model_mnistm2svhn_best_rgb.bin'
    model_path_label = 'predictor_model_mnistm2svhn_best_rgb.bin'
if "usps" in test_workspace_dir:
    model_path_feature = 'extractor_model_mnistm2usps_best_rgb.bin'
    model_path_label = 'predictor_model_mnistm2usps_best_rgb.bin'


class p3Data(Dataset):
    def __init__(self, fnames, labels, transform):
        self.transform = transform
        self.fnames = fnames
        self.labels = labels
        self.num_samples = len(self.fnames)
        # self.df = pd.read_csv(csv_path)

    def __getitem__(self, idx):
        fname = self.fnames[idx]
        label = self.labels[idx]
        # fname = self.df[idx, 'image_name']
        # fname = glob.glob(os.path.join(root, '*'))
        img = torchvision.io.read_image(fname)
        img = self.transform(img)
        return img, label

    def __len__(self):
        return self.num_samples


def get_dataset(root, transform):
    # fnames = glob.glob(os.path.join(root, '*'))
    fnames = [file for file in os.listdir(root) if file.endswith('.png')]
    for i, file in enumerate(fnames):
        fnames[i] = os.path.join(root, file)
    fnames.sort()
    # print(fnames)
    labels = [0]*len(fnames)
    dataset = p3Data(fnames, labels, transform)
    return dataset, fnames

# autoAugment = [transforms.AutoAugment(policy=AutoAugmentPolicy.IMAGENET),
#          transforms.AutoAugment(policy=AutoAugmentPolicy.CIFAR10),
#          transforms.AutoAugment(policy=AutoAugmentPolicy.SVHN)]


test_transform1 = transforms.Compose([
    transforms.ToPILImage(),
    # transforms.Grayscale(),
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
])

test_transform2 = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Grayscale(3),
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
])

batch_size = 128
test_set, fnames = get_dataset(
    os.path.join(test_workspace_dir), test_transform2)
test_dataloader = DataLoader(
    test_set, batch_size=batch_size, shuffle=False, num_workers=0)


class FeatureExtractor(nn.Module):
    def __init__(self):
        super(FeatureExtractor, self).__init__()

        self.conv = nn.Sequential(
            nn.Conv2d(3, 64, 3, 1, 1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(64, 128, 3, 1, 1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(128, 256, 3, 1, 1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(256, 256, 3, 1, 1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(256, 512, 3, 1, 1),
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )

    def forward(self, x):
        x = self.conv(x).squeeze()
        return x


class LabelPredictor(nn.Module):
    def __init__(self):
        super(LabelPredictor, self).__init__()

        self.layer = nn.Sequential(
            nn.Linear(512, 512),
            nn.ReLU(),

            nn.Linear(512, 512),
            nn.ReLU(),

            nn.Linear(512, 10),
        )

    def forward(self, h):
        c = self.layer(h)
        return c


class DomainClassifier(nn.Module):
    def __init__(self):
        super(DomainClassifier, self).__init__()

        self.layer = nn.Sequential(
            nn.Linear(512, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),

            nn.Linear(512, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),

            nn.Linear(512, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),

            nn.Linear(512, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),

            nn.Linear(512, 1),
        )

    def forward(self, h):
        y = self.layer(h)
        return y


device = "cuda" if torch.cuda.is_available() else "cpu"

feature_extractor = FeatureExtractor().to(device)
label_predictor = LabelPredictor().to(device)

class_criterion = nn.CrossEntropyLoss()
domain_criterion = nn.BCEWithLogitsLoss()

optimizer_F = optim.Adam(feature_extractor.parameters())
optimizer_C = optim.Adam(label_predictor.parameters())


def test_epoch(test_dataloader, feature_extractor, label_predictor, output_dir, fnames):
    feature_extractor.eval()
    label_predictor.eval()
    result = []
    for batch in test_dataloader:
        imgs, labels = batch
        imgs = imgs.to(device)
        labels = labels.to(device)
        with torch.no_grad():
            logits = label_predictor(feature_extractor(imgs))
        x = torch.argmax(logits, dim=1).cpu().detach().numpy()
        result.append(x)
    result = np.concatenate(result)

    with open(output_dir, "w") as f:
        f.write("image_name,label\n")
        for i, pred in enumerate(result):
            f.write(f"{fnames[i].split('/')[-1]},{pred}\n")


feature_extractor.load_state_dict(torch.load(model_path_feature))
label_predictor.load_state_dict(torch.load(model_path_label))
label_predictor.eval()
feature_extractor.eval()
test_epoch(test_dataloader, feature_extractor,
           label_predictor, output_dir, fnames)
