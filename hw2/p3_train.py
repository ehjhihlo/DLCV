# -*- coding: utf-8 -*-
import logging
import numpy as np
from torchvision.transforms import AutoAugmentPolicy
from torch.utils.data.dataset import Dataset
from torch.utils.data import ConcatDataset, DataLoader, Subset
from torch import optim
from torchvision import models, transforms
import torchvision.transforms as transforms
import torchvision
from torchvision.transforms import functional as TF
import torch.nn.functional as F
import torch.nn as nn
import torch
from torch.autograd import Function
import matplotlib.pyplot as plt
import math
import pandas as pd
import random
import glob
import os
import cv2
"""DLCVHW2_p3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pyXQg320hHN6sFTziper7X4qtGAkn6zd
"""

# !gdown - -id 1YxkObGDlqZM0-9Zq-QMjk7q1vND4UJl3 - -output "data.zip"
# ! unzip data.zip

# import module


# seed setting

def same_seeds(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True


same_seeds(1126)

source_workspace_dir = './hw2_data/digits/mnistm/'
target_workspace_dir = './hw2_data/digits/svhn/'
# target_workspace_dir = './hw2_data/digits/usps/'


class p3Data(Dataset):
    def __init__(self, fnames, labels, transform):
        self.transform = transform
        self.fnames = fnames
        self.labels = labels
        self.num_samples = len(self.fnames)
        # self.df = pd.read_csv(csv_path)

    def __getitem__(self, idx):
        fname = self.fnames[idx]
        label = self.labels[idx]
        # fname = self.df[idx, 'image_name']
        # fname = glob.glob(os.path.join(root, '*'))
        img = torchvision.io.read_image(fname)
        img = self.transform(img)
        return img, label

    def __len__(self):
        return self.num_samples


def get_dataset(root, csvfile, transform):
    # fnames = glob.glob(os.path.join(root, '*'))
    # fnames.sort()
    data = pd.read_csv(csvfile)
    fnames = data['image_name'].tolist()
    fnames.sort()
    # print(fnames)
    for i in range(len(fnames)):
        fnames[i] = root + '/' + fnames[i]
    fnames.sort()
    # print(fnames)
    labels = data['label'].tolist()
    dataset = p3Data(fnames, labels, transform)
    return dataset

# autoAugment = [transforms.AutoAugment(policy=AutoAugmentPolicy.IMAGENET),
#          transforms.AutoAugment(policy=AutoAugmentPolicy.CIFAR10),
#          transforms.AutoAugment(policy=AutoAugmentPolicy.SVHN)]


source_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
])

# svhn
source_transform1 = transforms.Compose([
    transforms.ToPILImage(),
    transforms.AutoAugment(policy=AutoAugmentPolicy.SVHN),
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
])

source_transform2 = transforms.Compose([
    transforms.ToPILImage(),
    transforms.AutoAugment(policy=AutoAugmentPolicy.SVHN),
    transforms.RandomAffine(degrees=5, translate=(
        0.12, 0.12), scale=(0.8, 1.2)),
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
])

source_transform3 = transforms.Compose([
    transforms.ToPILImage(),
    transforms.AutoAugment(policy=AutoAugmentPolicy.SVHN),
    transforms.RandomAffine(degrees=5, translate=(0.1, 0.12), scale=(1, 1.2)),
    # transforms.Resize((32, 32)),
    transforms.RandomResizedCrop((32, 32), scale=(0.7, 1.0), ratio=(0.8, 1.2)),
    transforms.ToTensor(),
])

source_transform4 = transforms.Compose([
    transforms.ToPILImage(),
    transforms.AutoAugment(policy=AutoAugmentPolicy.SVHN),
    transforms.RandomAffine(degrees=10, translate=(0.1, 0.12), scale=(0.8, 1)),
    # transforms.Resize((32, 32)),
    transforms.RandomResizedCrop((32, 32), scale=(0.7, 1.0), ratio=(0.8, 1.2)),
    transforms.ToTensor(),
])

target_transform = transforms.Compose([
    transforms.ToPILImage(),
    # transforms.Grayscale(3), #usps
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
])

test_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((32, 32)),
    transforms.ToTensor(),
])

source_train_set = get_dataset(os.path.join(source_workspace_dir, 'data'), os.path.join(
    source_workspace_dir, 'train.csv'), source_transform)

source_train_set1 = get_dataset(os.path.join(source_workspace_dir, 'data'), os.path.join(
    source_workspace_dir, 'train.csv'), source_transform1)
source_train_set2 = get_dataset(os.path.join(source_workspace_dir, 'data'), os.path.join(
    source_workspace_dir, 'train.csv'), source_transform2)
source_train_set3 = get_dataset(os.path.join(source_workspace_dir, 'data'), os.path.join(
    source_workspace_dir, 'train.csv'), source_transform3)
source_train_set4 = get_dataset(os.path.join(source_workspace_dir, 'data'), os.path.join(
    source_workspace_dir, 'train.csv'), source_transform4)

# svhn
source_train_set = ConcatDataset(
    [source_train_set, source_train_set1, source_train_set2, source_train_set3, source_train_set4])

target_train_set = get_dataset(os.path.join(target_workspace_dir, 'data'), os.path.join(
    target_workspace_dir, 'train.csv'), target_transform)
target_test_set = get_dataset(os.path.join(target_workspace_dir, 'data'), os.path.join(
    target_workspace_dir, 'train.csv'), target_transform)

batch_size = 128
source_dataloader = DataLoader(
    source_train_set, batch_size=batch_size, shuffle=True, num_workers=4)
target_dataloader = DataLoader(
    target_train_set, batch_size=batch_size, shuffle=True, num_workers=4)
test_dataloader = DataLoader(
    target_test_set, batch_size=batch_size, shuffle=False, num_workers=4)


class FeatureExtractor(nn.Module):
    def __init__(self):
        super(FeatureExtractor, self).__init__()

        self.conv = nn.Sequential(
            nn.Conv2d(3, 64, 3, 1, 1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(64, 128, 3, 1, 1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(128, 256, 3, 1, 1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(256, 256, 3, 1, 1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.MaxPool2d(2),

            nn.Conv2d(256, 512, 3, 1, 1),
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.MaxPool2d(2)
        )

    def forward(self, x):
        x = self.conv(x).squeeze()
        return x


class LabelPredictor(nn.Module):
    def __init__(self):
        super(LabelPredictor, self).__init__()

        self.layer = nn.Sequential(
            nn.Linear(512, 512),
            nn.ReLU(),

            nn.Linear(512, 512),
            nn.ReLU(),

            nn.Linear(512, 10),
        )

    def forward(self, h):
        c = self.layer(h)
        return c


class DomainClassifier(nn.Module):
    def __init__(self):
        super(DomainClassifier, self).__init__()

        self.layer = nn.Sequential(
            nn.Linear(512, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),

            nn.Linear(512, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),

            nn.Linear(512, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),

            nn.Linear(512, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),

            nn.Linear(512, 1),
        )

    def forward(self, h):
        y = self.layer(h)
        return y


device = "cuda" if torch.cuda.is_available() else "cpu"

feature_extractor = FeatureExtractor().to(device)
label_predictor = LabelPredictor().to(device)
domain_classifier = DomainClassifier().to(device)

class_criterion = nn.CrossEntropyLoss()
domain_criterion = nn.BCEWithLogitsLoss()

optimizer_F = optim.Adam(feature_extractor.parameters())
optimizer_C = optim.Adam(label_predictor.parameters())
optimizer_D = optim.Adam(domain_classifier.parameters())


def train_epoch(source_dataloader, target_dataloader, lamb):
    '''
      Args:
        source_dataloader: source data的dataloader
        target_dataloader: target data的dataloader
        lamb: control the balance of domain adaptatoin and classification.
    '''

    # D loss: Domain Classifier的loss
    # F loss: Feature Extrator & Label Predictor的loss
    running_D_loss, running_F_loss = 0.0, 0.0
    total_hit, total_num = 0.0, 0.0

    for i, ((source_data, source_label), (target_data, _)) in enumerate(zip(source_dataloader, target_dataloader)):
        # print(source_data.shape)
        # print(target_data.shape)
        source_data = source_data.to(device)
        source_label = source_label.to(device)
        target_data = target_data.to(device)

        # Mixed the source data and target data, or it'll mislead the running params
        #   of batch_norm. (runnning mean/var of soucre and target data are different.)
        mixed_data = torch.cat([source_data, target_data], dim=0)
        domain_label = torch.zeros(
            [source_data.shape[0] + target_data.shape[0], 1]).to(device)
        # set domain label of source data to be 1.
        domain_label[:source_data.shape[0]] = 1

        # Step 1 : train domain classifier
        feature = feature_extractor(mixed_data)
        # We don't need to train feature extractor in step 1.
        # Thus we detach the feature neuron to avoid backpropgation.
        domain_logits = domain_classifier(feature.detach())
        loss = domain_criterion(domain_logits, domain_label)
        running_D_loss += loss.item()
        loss.backward()
        optimizer_D.step()

        # Step 2 : train feature extractor and label classifier
        class_logits = label_predictor(feature[:source_data.shape[0]])
        domain_logits = domain_classifier(feature)
        # loss = cross entropy of classification - lamb * domain binary cross entropy.
        #  The reason why using subtraction is similar to generator loss in disciminator of GAN
        loss = class_criterion(class_logits, source_label) - \
            lamb * domain_criterion(domain_logits, domain_label)
        running_F_loss += loss.item()
        loss.backward()
        optimizer_F.step()
        optimizer_C.step()

        optimizer_D.zero_grad()
        optimizer_F.zero_grad()
        optimizer_C.zero_grad()

        total_hit += torch.sum(torch.argmax(class_logits,
                                            dim=1) == source_label).item()
        total_num += source_data.shape[0]
        print(i, end='\r')

    return running_D_loss / (i+1), running_F_loss / (i+1), total_hit / total_num


def test_epoch(test_dataloader):
    test_accs = []
    for batch in test_dataloader:
        imgs, labels = batch
        imgs = imgs.cuda()
        labels = labels.cuda()
        with torch.no_grad():
            logits = label_predictor(feature_extractor(imgs))
        acc = (logits.argmax(dim=-1) == labels).float().mean()
        test_accs.append(acc)
    test_acc = sum(test_accs) / len(test_accs)
    return test_acc


class Semi(Dataset):
    def __init__(self, imgs, labels):
        super(Semi, self).__init__()
        self.imgs = imgs
        self.labels = labels

    def __getitem__(self, index):
        img = self.imgs[index]
        label = self.labels[index]
        return img, label

    def __len__(self):
        return len(self.imgs)


def get_pseudo_labels(dataset, feature_extractor, label_predictor, threshold=0.999):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)
    feature_extractor.eval()
    label_predictor.eval()
    softmax = nn.Softmax(dim=-1)
    labels = []
    imgs = []

    for batch in data_loader:
        img, _ = batch
        with torch.no_grad():
            logits = label_predictor(feature_extractor(img.to(device)))
        probs = softmax(logits)

        for i, p in enumerate(probs):
            if (max(p) > threshold):
                imgs.append(img[i])
                labels.append(torch.argmax(p).item())

    if (len(img) % batch_size == 1):
        imgs = imgs[0: -1]
        labels = labels[0: -1]
    dataset = Semi(imgs, labels)

    feature_extractor.train()
    label_predictor.train()
    print(f"{len(imgs)} images added into training set!")
    return dataset


# train 300 epochs
num_epochs = 200
do_semi = False
threshold = 0.99
best_acc = 0
best_epoch = 0

model_dir = 'model_semi'
os.makedirs(model_dir, exist_ok=True)

for epoch in range(num_epochs):
    lamb = (2 / (1 + math.exp(-10 * epoch / num_epochs))) - 1
    # You should chooose lamnda cleverly.
    # if do_semi and test_acc > 0.3:
    if do_semi:
        print("Start doing semisupervising!")
        pseudo_set = get_pseudo_labels(
            target_train_set, feature_extractor, label_predictor, threshold)
        concat_dataset = ConcatDataset([source_train_set, pseudo_set])
        source_dataloader = DataLoader(
            concat_dataset, batch_size=128, shuffle=True)

    label_predictor.train()
    feature_extractor.train()
    train_D_loss, train_F_loss, train_acc = train_epoch(
        source_dataloader, target_dataloader, lamb)

    label_predictor.eval()
    feature_extractor.eval()
    test_acc = test_epoch(test_dataloader)
    print('Test Acc: {:6.4f}'.format(test_acc))
    if test_acc > best_acc:
        torch.save(feature_extractor.state_dict(), os.path.join(
            model_dir, f'extractor_model_mnistm2svhn_best_rgb.bin'))
        torch.save(label_predictor.state_dict(), os.path.join(
            model_dir, f'predictor_model_mnistm2svhn_best_rgb.bin'))
        # torch.save(feature_extractor.state_dict(), os.path.join(
        #     model_dir, f'extractor_model_mnistm2usps_best_rgb.bin'))
        # torch.save(label_predictor.state_dict(), os.path.join(
        #     model_dir, f'predictor_model_mnistm2usps_best_rgb.bin'))
        best_acc = test_acc
        best_epoch = epoch
        print('Best Model Saved!!!')
    torch.save(feature_extractor.state_dict(), os.path.join(
        model_dir, f'extractor_model_mnistm2svhn_rgb.bin'))
    torch.save(label_predictor.state_dict(), os.path.join(
        model_dir, f'predictor_model_mnistm2svhn_rgb.bin'))
    # torch.save(feature_extractor.state_dict(), os.path.join(
    #     model_dir, f'extractor_model_mnistm2usps_rgb.bin'))
    # torch.save(label_predictor.state_dict(), os.path.join(
    #     model_dir, f'predictor_model_mnistm2usps_rgb.bin'))
    print('epoch {:>3d}: train D loss: {:6.4f}, train F loss: {:6.4f}, acc {:6.4f}'.format(
        epoch+1, train_D_loss, train_F_loss, train_acc))
    print(f'Best Accuracy = {best_acc} at epoch = {best_epoch+1}')
    if test_acc > 0.36:
        do_semi = True
    if test_acc < 0.36:
        do_semi = False
