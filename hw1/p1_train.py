# -*- coding: utf-8 -*-
"""DLCV_HW1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SJ_0n18U1grSxDJ6_613vIgtjgDnpIYK
    
Ref: ML2022 Spring HW3
https://colab.research.google.com/drive/15hMu9YiYjE_6HY99UXon2vKGk2KwugWu
"""

# !nvidia-smi
# Import necessary packages.
import glob
import numpy as np
import pandas as pd
import torch
import os
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.models as models
from torchvision.transforms import AutoAugmentPolicy
from PIL import Image
from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset
from torchvision.datasets import DatasetFolder, VisionDataset
from tqdm.auto import tqdm
import random

def same_seeds(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True
same_seeds(87)

autoAugment = [transforms.AutoAugment(policy=AutoAugmentPolicy.IMAGENET),
         transforms.AutoAugment(policy=AutoAugmentPolicy.CIFAR10),
         transforms.AutoAugment(policy=AutoAugmentPolicy.SVHN)]

# train_tfm = transforms.Compose([
# 	transforms.Resize((128, 128)),
#   transforms.ColorJitter(0.3, 0.2, 0.15),
#   transforms.RandomHorizontalFlip(p=0.6),
#   transforms.AutoAugment(policy=AutoAugmentPolicy.IMAGENET),
# 	transforms.ToTensor(),
#   transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
# ])

train_tfm1 = transforms.Compose([
	transforms.Resize((128, 128)),
  transforms.ColorJitter(0.3, 0.2, 0.15),
  transforms.RandomHorizontalFlip(p=0.6),
  transforms.AutoAugment(policy=AutoAugmentPolicy.IMAGENET),
	transforms.ToTensor(),
  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

train_tfm2 = transforms.Compose([
	transforms.Resize((128, 128)),
  transforms.ColorJitter(0.3, 0.2, 0.15),
  transforms.RandomHorizontalFlip(p=0.6),
  transforms.AutoAugment(policy=AutoAugmentPolicy.CIFAR10),
	transforms.ToTensor(),
  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

train_tfm3 = transforms.Compose([
	transforms.Resize((128, 128)),
  transforms.ColorJitter(0.3, 0.2, 0.15),
  transforms.RandomHorizontalFlip(p=0.6),
  transforms.AutoAugment(policy=AutoAugmentPolicy.SVHN),
	transforms.ToTensor(),
  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

test_tfm = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

class p1Data(Dataset):
    def __init__(self, path, tfm=test_tfm, files = None):
        super(p1Data).__init__()
        self.path = path
        self.files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(".png")])
        if files != None:
            self.files = files
        print(path)
        self.transform = tfm
    
    def __getitem__(self,idx):
        fname = self.files[idx]
        im = Image.open(fname)
        im = self.transform(im)
        #im = self.data[idx]
        try:
            label = int(fname.split("/")[-1].split("_")[0])
        except:
            label = -1 # test has no label
        return im,label
    def __len__(self):
        return len(self.files)

batch_size = 64
_dataset_dir = "./hw1_data/p1_data"
# Construct datasets.
train_set1 = p1Data(os.path.join(_dataset_dir,"train_50"), tfm=train_tfm1)
train_set2 = p1Data(os.path.join(_dataset_dir,"train_50"), tfm=train_tfm2)
train_set3 = p1Data(os.path.join(_dataset_dir,"train_50"), tfm=train_tfm3)
train_set = ConcatDataset([train_set1, train_set2, train_set3])
# train_set = p1Data(os.path.join(_dataset_dir,"train_50"), tfm=train_tfm)
valid_set = p1Data(os.path.join(_dataset_dir,"val_50"), tfm=test_tfm)
train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)
valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)

batch_size = 64
_dataset_dir = "./hw1_data/p1_data"

print('# images in trainset:', len(train_set)) 
print('# images in validationset:', len(valid_set))

device = "cuda" if torch.cuda.is_available() else "cpu"

# Model A: Resnet34
'''
ref: https://www.kaggle.com/code/poonaml/building-resnet34-from-scratch-using-pytorch/notebook
'''

class BasicBlock(nn.Module):
    expansion = 1
    def __init__(self, inplanes, planes, stride=1, downsample=None):
        super().__init__()
        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,
                     padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,
                     padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(planes)
        self.downsample = downsample
        self.stride = stride

    def forward(self, x):
        identity = x
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        if self.downsample is not None:
            identity = self.downsample(x)
        out += identity
        out = self.relu(out)

        return out

class ResNet(nn.Module):
    def __init__(self, block, layers, num_classes=50):
        super().__init__()      
        self.inplanes = 64
        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,
                               bias=False)
        self.bn1 = nn.BatchNorm2d(self.inplanes)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
        self.layer1 = self._make_layer(block, 64, layers[0])
        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)
        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)
        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512 , num_classes)

    def _make_layer(self, block, planes, blocks, stride=1):
        downsample = None  
        if stride != 1 or self.inplanes != planes:
            downsample = nn.Sequential(
                nn.Conv2d(self.inplanes, planes, 1, stride, bias=False),
                nn.BatchNorm2d(planes),
            )
        layers = []
        layers.append(block(self.inplanes, planes, stride, downsample))   
        self.inplanes = planes   
        for _ in range(1, blocks):
            layers.append(block(self.inplanes, planes))
        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.conv1(x)           # 224x224
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)         # 112x112
        x = self.layer1(x)          # 56x56
        x = self.layer2(x)          # 28x28
        x = self.layer3(x)          # 14x14
        x = self.layer4(x)          # 7x7
        x = self.avgpool(x)         # 1x1
        x = torch.flatten(x, 1)     # remove 1 X 1 grid and make vector of tensor shape 
        x = self.fc(x)
        return x

def resnet34():
    layers=[3, 4, 6, 3]
    model = ResNet(BasicBlock, layers)
    return model

# model = resnet34().to(device)

# Model B: EfficientNet_B4(with pretrained weight)
model = models.efficientnet_b4(pretrained=True, weights=models.efficientnet.EfficientNet_B2_Weights).to(device)
model.classifier = nn.Sequential(
    nn.Dropout(p=0.4, inplace=True),
    nn.Linear(in_features=1792, out_features=50, bias=True),
    ).to(device)

n_epochs = 100
patience = 30    
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5) 
stale = 0
best_acc = 0

for epoch in range(n_epochs):
    # ---------- Training ----------
    model.train()

    train_loss = []
    train_accs = []

    for batch in tqdm(train_loader):
        imgs, labels = batch
        logits = model(imgs.to(device))
        loss = criterion(logits, labels.to(device))
        optimizer.zero_grad()
        loss.backward()
        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)
        optimizer.step()
        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()
        train_loss.append(loss.item())
        train_accs.append(acc)
        
    train_loss = sum(train_loss) / len(train_loss)
    train_acc = sum(train_accs) / len(train_accs)

    # Print the information.
    print(f"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}")

    # ---------- Validation ----------
    model.eval()

    valid_loss = []
    valid_accs = []

    for batch in tqdm(valid_loader):
        imgs, labels = batch
        with torch.no_grad():
            logits = model(imgs.to(device))

        loss = criterion(logits, labels.to(device))
        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()

        valid_loss.append(loss.item())
        valid_accs.append(acc)

    valid_loss = sum(valid_loss) / len(valid_loss)
    valid_acc = sum(valid_accs) / len(valid_accs)

    print(f"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}")


    if epoch == 1:
        torch.save(model.state_dict(), "p1_Model_epoch1.ckpt")
    if epoch == 30:
        torch.save(model.state_dict(), "p1_Model_epoch30.ckpt")
    if epoch == 100:
        torch.save(model.state_dict(), "p1_Model_epoch100.ckpt")
    # save models
    if valid_acc > best_acc:
        print(f"Best model found at epoch {epoch+1}, saving model")
        torch.save(model.state_dict(), "p1_Model.ckpt") # only save best to prevent output memory exceed error
        best_acc = valid_acc
        stale = 0
    else:
        stale += 1
        if stale > patience:
            print(f"No improvment for {patience} epochs, stop training")
            break